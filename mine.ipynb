{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\CRSP\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "D:\\anaconda3\\envs\\CRSP\\lib\\site-packages\\sklearn\\utils\\validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from models.TC import TC\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"  #!!\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"  #!!\n",
    "import numpy as np\n",
    "import random\n",
    "from models.TC import TC\n",
    "from models.utils_model import *\n",
    "from models.pic import PIC_no, PIC_RBP\n",
    "from data_preprocessing.CRBP.dataloader import data_generator\n",
    "from models.model import base_Model\n",
    "from config_files.circrna_configs import Config as Configs\n",
    "from models.HDRNet import HDRNet\n",
    "\n",
    "coden_dict = {'AGO1': 0, 'AGO2': 1, 'AGO3': 2, 'ALKBH5': 3, 'AUF1': 4, 'C17ORF85': 5, 'C22ORF28': 6, 'CAPRIN1': 7,\n",
    "              'DGCR8': 8, 'EIF4A3': 9, 'EWSR1': 10,\n",
    "              'FMRP': 11, 'FOX2': 12, 'FUS': 13, 'FXR1': 14, 'FXR2': 15, 'HNRNPC': 16, 'HUR': 17, 'IGF2BP1': 18,\n",
    "              'IGF2BP2': 19, 'IGF2BP3': 20,\n",
    "              'LIN28A': 21, 'LIN28B': 22, 'METTL3': 23, 'MOV10': 24, 'PTB': 25, 'PUM2': 26, 'QKI': 27, 'SFRS1': 28,\n",
    "              'TAF15': 29, 'TDP43': 30,\n",
    "              'TIA1': 31, 'TIAL1': 32, 'TNRC6': 33, 'U2AF65': 34, 'WTAP': 35, 'ZC3H7B': 36,\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIC_no(\n",
       "  (Wk): ModuleList(\n",
       "    (0): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (2): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (3): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (4): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (5): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (6): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (7): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (8): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (9): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (10): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (11): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (12): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (13): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (14): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (15): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (16): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (17): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (18): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (19): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (20): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (21): Linear(in_features=100, out_features=128, bias=True)\n",
       "  )\n",
       "  (lsoftmax): LogSoftmax(dim=1)\n",
       "  (projection_head_pic): Sequential(\n",
       "    (0): Conv1d(128, 1, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=147, out_features=100, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=100, out_features=20, bias=True)\n",
       "    (6): ReLU()\n",
       "    (7): Linear(in_features=20, out_features=2, bias=True)\n",
       "    (8): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "configs = Configs()\n",
    "model = base_Model(configs).to(device)\n",
    "temporal_contr_model = TC(configs, device).to(device)\n",
    "pic_model_NO = PIC_no(configs, device).to(device)\n",
    "pic_model_RBP = PIC_RBP(configs, device).to(device)\n",
    "hdrnet = HDRNet()\n",
    "\n",
    "model.eval()\n",
    "temporal_contr_model.eval()\n",
    "pic_model_RBP.eval()\n",
    "pic_model_NO.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_type = 'WTAP'\n",
    "\n",
    "data_path = f\"./data/circRNA-RBP/{data_type}\"\n",
    "train_dl, test_dl = data_generator(data_type, configs)\n",
    "\n",
    "for batch_idx, (data1, data2, data3, data4, data5, labels, idxs) in enumerate(train_dl):\n",
    "\n",
    "    data1, data2, data3, data4, data5 = data1.float().to(device), data2.float().to(device), data3.float().to(\n",
    "        device), data4.float().to(device), data5.float().to(device)\n",
    "\n",
    "    labels = labels.long().to(device)\n",
    "    # np.savetxt('labels.txt',labels)\n",
    "\n",
    "    idxs = idxs.long().to(device)\n",
    "\n",
    "    RBP = np.loadtxt('./rbp_data/37RBP_37_512_5.txt',\n",
    "                     delimiter=',').reshape((37, 512, 5))\n",
    "\n",
    "    RBP_PART = RBP[coden_dict[data_type]].reshape((1, 512, 5))  # WTAP\n",
    "\n",
    "    index = coden_dict[data_type]\n",
    "    available_indices = list(range(len(coden_dict)))\n",
    "    available_indices.remove(index)\n",
    "\n",
    "    RBP_1_index = random.choice(available_indices)\n",
    "    available_indices.remove(RBP_1_index)\n",
    "\n",
    "    RBP_2_index = random.choice(available_indices)\n",
    "\n",
    "    RBP_1 = RBP[RBP_1_index].reshape((1, 512, 5))\n",
    "    RBP_2 = RBP[RBP_2_index].reshape((1, 512, 5))\n",
    "\n",
    "    RBP_ten = torch.from_numpy(RBP_PART)\n",
    "    RBP_ten1 = torch.from_numpy(RBP_1)\n",
    "    RBP_ten2 = torch.from_numpy(RBP_2)\n",
    "\n",
    "    dataR = RBP_ten.float()\n",
    "    data_RBP1 = RBP_ten1.float()\n",
    "    data_RBP2 = RBP_ten2.float()\n",
    "\n",
    "    features1 = model(data1, tag=1)\n",
    "    features2 = model(data2, tag=2)\n",
    "    features3 = model(data3, tag=3)\n",
    "    features4 = model(data4, tag=3)\n",
    "\n",
    "    features5 = model(data5, tag=5)\n",
    "\n",
    "    # output = hdrnet(features3)\n",
    "\n",
    "    output = hdrnet(features1, features2, features3, features4)\n",
    "    # output = hdrnet(features1, features2, features3,features4,features5)\n",
    "\n",
    "    # output1 = output.detach().numpy()\n",
    "    # with open('output.txt', 'w') as outfile:\n",
    "    #     for slice_2d in output1:\n",
    "    #         np.savetxt(outfile, slice_2d, fmt='%f', delimiter=',')\n",
    "\n",
    "    RBP_f = model(dataR, tag=4)\n",
    "    RBP_f1 = model(data_RBP1, tag=4)\n",
    "    RBP_f2 = model(data_RBP2, tag=4)\n",
    "\n",
    "    a = features1.size(-1) + features2.size(-1) + features3.size(-1) + features4.size(-1)\n",
    "\n",
    "    result = torch.zeros(64, 128, a + 5)\n",
    "\n",
    "    zero_counter = 0\n",
    "    one_counter = 0\n",
    "\n",
    "    for idx, label in enumerate(labels):\n",
    "\n",
    "        if label == 1:\n",
    "\n",
    "            one_counter += 1\n",
    "            result[idx, :, :a] = output[idx, :, :]\n",
    "            result[idx, :, a:] = RBP_f[0, :, :]\n",
    "        else:\n",
    "            result[idx, :, :a] = output[idx, :, :]\n",
    "            if zero_counter % 2 == 0:\n",
    "                result[idx, :, a:] = RBP_f1[0, :, :]\n",
    "            else:\n",
    "                result[idx, :, a:] = RBP_f2[0, :, :]\n",
    "\n",
    "            zero_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_seq = []\n",
    "with open('datasets/circRNA-RBP/' + data_type + '/positive') as f:\n",
    "    for line in f:\n",
    "        if '>' not in line:\n",
    "            data_seq.append((line.strip()).replace('T', 'U'))\n",
    "with open('datasets/circRNA-RBP/' + data_type + '/negative') as f:\n",
    "    for line in f:\n",
    "        if '>' not in line:\n",
    "            data_seq.append((line.strip()).replace('T', 'U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([158, 404, 754, 432, 113,  53,  39, 572, 563, 733, 124, 616,  36, 689,\n",
       "         261, 256, 835, 631, 415, 608, 646, 511, 123, 620, 721, 516, 116, 152,\n",
       "         544, 884, 541, 619, 671, 506, 650, 776,  35, 716, 568, 500, 397,  47,\n",
       "         846, 687, 702, 118, 330,  82, 184, 136, 681, 536, 576,  60,  11, 602,\n",
       "          48, 593, 720, 350, 831, 339, 452, 796]),\n",
       " tensor(158),\n",
       " 'CAGUUAUGGAGAGGAGUGUUUAGGGGUGUGGUUGUCUACCUGGAAUGGGAUGAGAAGCUCUGCUGCCCAAAGUGUUUCCUGUUUCAGGGAAAGAUUUCUAU')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# print(test_emb)\n",
    "# e = shap.GradientExplainer(temporal_contr_model,\n",
    "#                            [test_f1,test_f2,test_f3,test_f4,test_RBP_f,test_RBP_f1,test_RBP_f2,test_output,test_labels])\n",
    "\n",
    "# e = shap.GradientExplainer(temporal_contr_model,\n",
    "#                            [test_f1,test_f2,test_f3,test_f4,new_RBP_f,new_RBP_f1,new_RBP_f2,test_output,test_labels])\n",
    "\n",
    "# e = shap.GradientExplainer(pic_model_RBP, [result])\n",
    "e = shap.GradientExplainer(pic_model_NO, [output])\n",
    "\n",
    "\n",
    "i = 0  # Plot which sample number\n",
    "\n",
    "# Interpretation of individual samples\n",
    "idx_seq = idxs[i]\n",
    "# idx_seq = 274\n",
    "# shap_values = e.shap_values([test_f1[i:i+1], test_f2[i:i+1],test_f3[i:i+1],test_f4[i:i+1],new_RBP_f[i:i+1],new_RBP_f1[i:i+1],new_RBP_f2[i:i+1],test_output[i:i+1],test_labels[i:i+1]])\n",
    "\n",
    "# shap_values = e.shap_values([result[i:i + 1]])\n",
    "shap_values = e.shap_values([output[i:i + 1]])  # Calculate SHAP values for specified samples\n",
    "\n",
    "# shap_values = e.shap_values([test_f1[i:i+1], test_f2[i:i+1],test_f3[i:i+1],test_f4[i:i+1]])\n",
    "# shap_values = e.shap_values([a,test_RBP_f,test_RBP_f1,test_RBP_f2,test_output[i:i+1]])\n",
    "\n",
    "# input_seq = sequences[i]\n",
    "\n",
    "input_seq = data_seq[idx_seq]\n",
    "\n",
    "# input_struct = test_struc[i]\n",
    "\n",
    "bert_attention_data = np.max(shap_values[0], axis=1)\n",
    "# bert_attention_data = np.max(shap_values[1], axis=1)\n",
    "\n",
    "# Create a new array to store the processed bert attention data\n",
    "new_bert_attention_data = np.zeros((1, 101))\n",
    "for j in range(101):\n",
    "    if j == 0:\n",
    "        new_bert_attention_data[0, j] = bert_attention_data[0, j]\n",
    "    elif j == 1:\n",
    "        new_bert_attention_data[0, j] = (bert_attention_data[0, j - 1] + bert_attention_data[0, j]) / 2\n",
    "    elif j == 99:\n",
    "        new_bert_attention_data[0, j] = (bert_attention_data[0, j - 1] + bert_attention_data[0, j - 2]) / 2\n",
    "    elif j == 100:\n",
    "        new_bert_attention_data[0, j] = bert_attention_data[0, j - 2]\n",
    "    else:\n",
    "        new_bert_attention_data[0, j] = (bert_attention_data[0, j - 2] + bert_attention_data[0, j - 1] +\n",
    "                                         bert_attention_data[0, j]) / 3\n",
    "\n",
    "bert_attention_data = new_bert_attention_data\n",
    "# The processed BERT attention data is combined with the input sequence data\n",
    "bert_attention_data = convert_one_hot2([input_seq], bert_attention_data[0, :]).transpose(1, 0, 2).squeeze()\n",
    "#\n",
    "#\n",
    "# struc_attention_data = shap_values[1][0]\n",
    "\n",
    "#\n",
    "# Concatenate BERT attention data and structural attention data\n",
    "W = bert_attention_data\n",
    "\n",
    "onehot = convert_one_hot([input_seq]).squeeze()\n",
    "X = onehot\n",
    "#\n",
    "# X = np.concatenate([onehot, input_struct.cpu().detach().numpy()], axis=0)\n",
    "\n",
    "idxs, idx_seq, input_seq\n",
    "\n",
    "# df = pd.DataFrame(data) #, columns=sss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the salience map of the selected sample\n",
    "import models.visualize as visualize\n",
    "\n",
    "# visualize.plot_saliency(X, W, nt_width=100, norm_factor=3, str_null=str_null, outdir=\"results/high_attention_region_plot/out4.png\")\n",
    "visualize.plot_saliency(X, W, nt_width=100, norm_factor=3, str_null=None, outdir=\"pic/test.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plot the salience map\n",
    "![pic_salience_map](./pic/test.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b6bc36ae4bc4d7e7d3fbbfe91bd00d644eb04fda392dd3dae0e564915faaa43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
